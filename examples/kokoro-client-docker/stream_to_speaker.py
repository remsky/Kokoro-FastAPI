import sys
import time
from pathlib import Path
import os
import argparse
import requests
from urllib.parse import urljoin
import pyaudio
from openai import OpenAI


def _parse_arg():
    parser = argparse.ArgumentParser(
        description="Save generated audio to file",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "--base_url",
        default=None,
        type=str,
        required=True,
        help="The base URL to TTS server, ex: http://host.docker.internal:8880/v1"
    )
    parser.add_argument(
        "--api_key",
        default="not-needed-for-local",
        type=str,
        help="The API Key for TTS server"
    )
    parser.add_argument(
        "--model",
        default="kokoro",
        type=str,
        help="The model to use, current support [kokoro, tts-1, tts-1-hd]"
    )
    parser.add_argument(
        "--voice",
        default="af_bella",
        type=str,
        help="The voice to use. Can use multiple voices, ex: af_alloy+zm_yunyang"
    )
    parser.add_argument(
        "--response_format",
        default="pcm",
        type=str,
        help="The format to audio in. Supported formats are [mp3, opus, aac, flac, wav, pcm]."
    )
    parser.add_argument(
        "--tts_output_rate",
        default=24000,
        type=int,
        help="The sample rate of the audio that generated by TTS model"
    )
    parser.add_argument(
        "--speed",
        default=1.0,
        type=float,
        help="The speed of the generated audio. Select a value from 0.25 to 4.0. 1.0 is the default."
    )
    parser.add_argument(
        "--text_input",
        default="Hi, I am a text-to-speech assistant.",
        type=str,
        help="The input text"
    )
    parser.add_argument(
        "--list_voices",
        action="store_true",
        help="List the voices."
    )
    parser.add_argument(
        "--check_audio_devices",
        action="store_true",
        help="Check audio devices"
    )
    args = parser.parse_args()    
    return args


def _list_available_voices(base_url: str):
    url=urljoin(base_url, '/v1/audio/voices')
    response = requests.get(url=url)
    return response.json()


def _check_params(
    base_url: str,
    model: str,
    voices: str,
    response_format: str,
    speed: float,
    ):
    # Check server
    url=urljoin(base_url, '/health')
    response = requests.get(url=url)
    if not response.json()['status'] == 'healthy':
        print(f"Server unhealthy: {base_url}")
        sys.exit(1)

    # Check model
    url=urljoin(base_url, '/v1/models')
    response = requests.get(url=url)
    model_names = [d['id'] for d in response.json()['data']]
    if not model in model_names:
        print(f"Incorrect model name: {model}")
        sys.exit(1)

    # Check voices
    available_voices = _list_available_voices(base_url=base_url)['voices']
    vs = voices.split('+')
    for v in vs:
        if not v in available_voices:
            print(f"Incorrect model name: {v}")
            sys.exit(1)
    
    # Check response format
    if not response_format in ['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm']:
        print(f"Incorrect response format: {response_format}")
        sys.exit(1)

    # Check speed
    if not speed >= 0.25 or not speed <= 4.0:
        print(f"Incorrect speed: {speed}")
        sys.exit(1)


def _check_audio_devices() -> None:
    # --- 初始化 PyAudio 並列出設備信息 ---
    pa = pyaudio.PyAudio()
    # 打印 PyAudio 當前選擇的默認音訊後端 (Host API)，例如 ALSA 或 PulseAudio
    # 理想情況下，由於我們的配置，它應該能直接檢測到 PulseAudio，但即使顯示 ALSA，
    # /etc/asound.conf 的配置也可能使其工作。
    print("PyAudio Initialized. Default Host API:", pa.get_default_host_api_info()['name'])

    print("\nAvailable output devices:")
    default_output_device_index = -1
    try:
        # 嘗試獲取默認的輸出設備信息
        default_info = pa.get_default_output_device_info()
        default_output_device_index = default_info['index']
        print(f"Default Output Device Info:")
        print(f"  Index: {default_info['index']}")
        print(f"  Name: {default_info['name']}")
        print(f"  Host API: {pa.get_host_api_info_by_index(default_info['hostApi'])['name']}")
        print(f"  Max Output Channels: {default_info['maxOutputChannels']}")
        print(f"  Default Sample Rate: {default_info['defaultSampleRate']}")
    except IOError as e:
        # 如果找不到默認設備 (例如 PulseAudio 連接失敗且沒有 ALSA 權限)，會打印錯誤
        print(f"Could not get default output device info: {e}")

    print("\nAll Devices:")
    device_found = False
    # 遍歷 PyAudio 檢測到的所有音訊設備
    for i in range(pa.get_device_count()):
        device_found = True
        info = pa.get_device_info_by_index(i)
        host_api_info = pa.get_host_api_info_by_index(info['hostApi'])
        print(f"  Index {i} - Name: {info.get('name')}, Host API: {host_api_info['name']}, Outputs: {info.get('maxOutputChannels')}, Default SR: {info.get('defaultSampleRate')}")
        # 檢查設備名稱或其 Host API 是否包含 'pulse'，標識出潛在的 PulseAudio 設備
        if 'pulse' in info.get('name', '').lower() or 'pulse' in host_api_info['name'].lower():
            print(f"    -> Potential PulseAudio device")
    if not device_found:
        print("  No devices found by PyAudio.")

    # 關閉這次的 PyAudio 實例，釋放資源
    pa.terminate()


def main(
    tts_output_rate: int,
    base_url: str,
    api_key: str,
    model: str,
    voice: str,
    response_format: str,
    text_input: str,
    speed: float,
    ) -> None:

    client = OpenAI(base_url=base_url, api_key=api_key)

    pa = pyaudio.PyAudio()
    print(f"Attempting to open audio stream via host sound server (PulseAudio/PipeWire) at {tts_output_rate} Hz")

    player_stream = None # 初始化播放流變量
    try:
        # 打開一個用於播放的音訊流 (output=True)
        # format=pyaudio.paInt16: 指定音訊數據格式為 16 位整數
        # channels=1: 單聲道
        # rate=tts_output_rate: 使用 TTS 的採樣率
        # output=True: 表明這是一個輸出流 (播放)
        # PyAudio 會嘗試使用默認的輸出設備。由於之前的配置 (user, PULSE_SERVER, asound.conf)，
        # 這個默認設備現在應該能成功指向並通過宿主機的 PulseAudio 播放。
        player_stream = pa.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=tts_output_rate,
            output=True
            )

        # 記錄開始時間，用於計算首字節延遲 (Time To First Byte, TTFB)
        start_time = time.time()

        # 使用 openai 客戶端連接 TTS 服務並請求串流輸出
        with client.audio.speech.with_streaming_response.create(
            model=model,  # 指定 TTS 模型
            voice=voice, # 指定使用的聲音
            # response_format="pcm": 指定響應格式為 PCM (Pulse Code Modulation)
            # PCM 是未壓縮的原始音訊數據，類似於 WAV 文件去掉頭部信息。
            # 這種格式適合直接餵給播放庫，如 PyAudio。
            response_format=response_format,
            input=text_input, # 要轉換為語音的文本
            speed=speed # 語速
        ) as response:
            # 打印從請求到收到第一個音訊數據塊的時間
            print(f"Time to first byte: {int((time.time() - start_time) * 1000)}ms")
            # 檢查音訊流是否成功打開並且處於活動狀態
            if player_stream is None or not player_stream.is_active():
                 print("Error: Audio stream is not active before writing.")
                 raise IOError("Audio stream could not be opened or is not active.")
            # 迭代接收到的音訊數據塊 (chunk)
            # chunk_size=1024: 每次迭代讀取 1024 字節的數據
            for chunk in response.iter_bytes(chunk_size=1024):
                # 將接收到的音訊數據塊寫入 PyAudio 的播放流
                # 這會將數據發送到 PulseAudio，最終在宿主機的揚聲器播放出來
                player_stream.write(chunk)

        # 打印完成整個串流播放所花費的總時間
        print(f"Done in {int((time.time() - start_time) * 1000)}ms.")

    # 捕捉在打開流或寫入數據時可能發生的 OS 級別錯誤 (例如設備無效、權限問題等)
    except OSError as e:
        print(f"Error opening stream or writing: {e}")
        print("Troubleshooting:")
        print(" - Is the PulseAudio socket correctly mounted in docker-compose.yml?")
        print(" - Is the PULSE_SERVER environment variable set correctly?")
        print(" - Is libpulse0 and libasound2-plugins installed in the container?")
        print(f" - Does the user ({os.getuid()}:{os.getgid()}) have permission for the socket?")
        print(" - Did PyAudio list a PulseAudio device or was /etc/asound.conf correctly set?")
        # 此處不 return，讓 finally 塊執行清理
    # finally 塊確保無論是否發生異常，資源都能被正確釋放
    finally:
        # 使用 try-except 包裹關閉流的操作，因為如果 open 失敗，player_stream 可能是 None
        try:
            # 檢查播放流是否存在且處於活動狀態
            if player_stream is not None and player_stream.is_active():
                # 停止音訊流
                player_stream.stop_stream()
                # 關閉音訊流，釋放相關資源
                player_stream.close()
                print("Audio stream stopped and closed.")
        except Exception as close_err:
             print(f"Error closing stream: {close_err}")

        # 使用 try-except 包裹終止 PyAudio 的操作
        try:
            # 檢查 PyAudio 實例是否存在
            if pa is not None:
                # 終止 PyAudio 實例，釋放 PortAudio 資源
                pa.terminate()
                print("PyAudio terminated.")
        except Exception as term_err:
            print(f"Error terminating PyAudio: {term_err}")    


if __name__ == "__main__":
    args = _parse_arg()
    
    if args.list_voices:
        print(_list_available_voices())
        sys.exit(0)
    
    if args.check_audio_devices:
        _check_audio_devices()
        sys.exit(0)

    _check_params(
        base_url=args.base_url,
        model=args.model,
        voices=args.voice,
        response_format=args.response_format,
        speed=args.speed,
    )

    base_url = args.base_url
    api_key=args.api_key
    model=args.model
    voice=args.voice
    response_format=args.response_format
    tts_output_rate=int(args.tts_output_rate)
    speed=float(args.speed)
    tts_output_rate=int(args.tts_output_rate)
    text_input=args.text_input

    main(
        tts_output_rate=tts_output_rate,
        base_url=base_url,
        api_key=api_key,
        model=model,
        voice=voice,
        text_input=text_input,
        response_format=response_format,
        speed=speed
    )