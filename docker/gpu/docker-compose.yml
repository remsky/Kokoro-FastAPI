name: zipvoice-tts-gpu
services:
  zipvoice-tts:
    # image: ghcr.io/fabul8/zipvoice-fastapi-gpu:v${VERSION}
    build:
      context: ../..
      dockerfile: docker/gpu/Dockerfile
    volumes:
      - ../../api:/app/api
      - zipvoice_cache:/app/api/src/voices/zipvoice_prompts
      - onnx_cache:/app/api/src/models/onnx_cache
      - tensorrt_cache:/app/api/src/models/tensorrt_cache
      - temp_files:/app/api/temp_files
    user: "1001:1001"  # Ensure container runs as UID 1001 (zipvoice user)
    ports:
      - "8880:8880"
    environment:
      # Core settings
      - PYTHONPATH=/app:/app/api
      - PYTHONUNBUFFERED=1
      - API_LOG_LEVEL=INFO

      # Device settings
      - USE_GPU=true
      - DEVICE_TYPE=cuda

      # Backend settings
      - ENABLE_KOKORO=false
      - ENABLE_ZIPVOICE=true
      - DEFAULT_BACKEND=zipvoice

      # ZipVoice core settings
      - ZIPVOICE_MODEL=zipvoice  # Options: zipvoice, zipvoice_distill, zipvoice_dialog, zipvoice_dialog_stereo
      - ZIPVOICE_NUM_STEPS=8  # Inference steps (1-32, lower=faster)
      - ZIPVOICE_REMOVE_LONG_SILENCE=true
      - ZIPVOICE_SPEED_MULTIPLIER=1.0
      - ZIPVOICE_MAX_PROMPT_DURATION=3.0
      - ZIPVOICE_ALLOW_URL_DOWNLOAD=true
      - ZIPVOICE_ALLOW_BASE64=true
      - ZIPVOICE_MAX_DOWNLOAD_SIZE_MB=10.0

      # Smart features
      - ENABLE_AUTO_TRANSCRIPTION=true
      - WHISPER_MODEL_SIZE=base  # Options: tiny, base, small, medium, large
      - ENABLE_SMART_TUNING=true
      - ENABLE_QUALITY_DETECTION=true
      - QUALITY_THRESHOLD=0.7

      # Optimization settings (enable as needed)
      - ENABLE_ONNX=false  # Set to true for 1.7x speedup
      - ENABLE_TENSORRT=false  # Set to true for 2.7x speedup (requires model conversion)

      # Paths
      - ZIPVOICE_CACHE_DIR=/app/api/src/voices/zipvoice_prompts
      - ONNX_CACHE_DIR=/app/api/src/models/onnx_cache
      - TENSORRT_CACHE_DIR=/app/api/src/models/tensorrt_cache

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    healthcheck:
      test: ["CMD", "./healthcheck.sh"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3

volumes:
  zipvoice_cache:
  onnx_cache:
  tensorrt_cache:
  temp_files:
