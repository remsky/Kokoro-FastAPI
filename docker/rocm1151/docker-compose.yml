name: kokoro-tts-rocm1151
services:
  kokoro-tts:
    # image: ghcr.io/remsky/kokoro-fastapi-rocm1151:v${VERSION}
    build:
      context: ../..
      dockerfile: docker/rocm1151/Dockerfile
    volumes:
      - ../../api:/app/api
      # These are caches used by ROCm's MIOpen library to speed up kernel selection
      - ./kokoro-tts/config:/root/.config/miopen
      - ./kokoro-tts/cache:/root/.cache/miopen
    user: "1001:1001"  # Ensure container runs as UID 1001 (appuser)
    ports:
      - "8880:8880"
    environment:
      - PYTHONPATH=/app:/app/api
      - USE_GPU=true
      - PYTHONUNBUFFERED=1
      - API_LOG_LEVEL=DEBUG
      - TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1
      # IMPORTANT: ROCm's MIOpen libray will be slow if it has to figure out the optimal kernel shapes for each model
      # See documentation on performancing tuning: https://github.com/ROCm/MIOpen/blob/develop/docs/conceptual/tuningdb.rst
      # 1. Run Kokoro once with the following environment variables set:
      - MIOPEN_FIND_MODE=3
      - MIOPEN_FIND_ENFORCE=3
      # 2. Generate various recordings using sample data (e.g. first couple paragraphs of Dracula); this will be slow
      # 3. Comment out/remove the previously set environment variables
      # 4. Add the following environment variables to enable caching of model shapes:
      # - MIOPEN_FIND_MODE=2
      # 5. Restart the container and run Kokoro again, it should be much faster
    devices:
      - /dev/dri
      - /dev/kfd
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    group_add:
      # NOTE: These groups are the group ids for: video and render
      # Numbers can be found via running: getent group $GROUP_NAME | cut -d: -f3
      - 42    #video
      - 992   #render
 

